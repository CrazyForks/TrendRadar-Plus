---
name: create-scraper
description: åˆ›å»ºè‡ªå®šä¹‰æ–°é—»æºçˆ¬è™«
---

# åˆ›å»ºæ–°é—»æºçˆ¬è™«

## æ¦‚è¿°
æœ¬ Skill æŒ‡å¯¼å¦‚ä½•ä¸ºæ–°çš„æ–°é—»ç½‘ç«™åˆ›å»ºè‡ªå®šä¹‰çˆ¬è™« Providerï¼Œå¹¶æä¾›**5ä¸ªç”Ÿäº§ç¯å¢ƒéªŒè¯çš„æˆåŠŸæ¡ˆä¾‹**ä½œä¸ºå‚è€ƒã€‚

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### å†³ç­–æµç¨‹

```mermaid
flowchart TD
    Start[æ–°ç½‘ç«™] --> Q1{æ•°æ®æ ¼å¼?}
    
    Q1 -->|JSON API| Q2{JSON ç»“æ„?}
    Q1 -->|HTML é¡µé¢| Q3{æ˜¯å¦åŠ¨æ€åŠ è½½?}
    
    Q2 -->|ç®€å•å¹³é“º| E1[sina_tech_roll.py]
    Q2 -->|å¤šé¢‘é“/åˆ†ç±»| E2[wallstreetcn_flash.py]
    Q2 -->|æ·±åº¦åµŒå¥—| E3[nba_schedule_recursive.py]
    
    Q3 -->|é™æ€ HTML| E4[aibase_news.py]
    Q3 -->|JS æ¸²æŸ“| E5[cls_depth_scraperapi.py]
    
    E1 & E2 & E3 & E4 & E5 --> Action[å¤åˆ¶æ¡ˆä¾‹å¹¶ä¿®æ”¹]
```

### æˆåŠŸæ¡ˆä¾‹åº“

| æ¡ˆä¾‹è„šæœ¬ | é€‚ç”¨åœºæ™¯ | æ¡ç›®æ•° | å…³é”®æŠ€æœ¯ |
|---------|---------|--------|----------|
| [wallstreetcn_flash.py](examples/wallstreetcn_flash.py) | å¤šé¢‘é“ API | 167+ | è½®è¯¢ã€å»é‡ã€æ’åº |
| [sina_tech_roll.py](examples/sina_tech_roll.py) | ç®€å• JSON API | 100+ | å‚æ•°è¯·æ±‚ã€æ—¶é—´æˆ³ |
| [aibase_news.py](examples/aibase_news.py) | é™æ€ HTML | 24+ | BS4 + Regex |
| [cls_depth_scraperapi.py](examples/cls_depth_scraperapi.py) | âš ï¸ åŠ¨æ€ JS æ¸²æŸ“ | 30+ | ScraperAPI |
| [nba_schedule_recursive.py](examples/nba_schedule_recursive.py) | åµŒå¥— JSON | 311+ | é€’å½’éå† |

ğŸ“– **è¯¦ç»†è¯´æ˜**: æŸ¥çœ‹ [examples/README.md](examples/README.md)

---

## ğŸ“ åˆ›å»ºæ­¥éª¤

###  1. åˆ†æç›®æ ‡ç½‘ç«™

**æ£€æŸ¥æ¸…å•**ï¼š
- [ ] æŸ¥çœ‹ç½‘ç»œè¯·æ±‚ï¼ˆChrome DevTools â†’ Networkï¼‰
- [ ] ç¡®å®šæ•°æ®æºï¼šJSON API / HTML / åŠ¨æ€JS
- [ ] è®°å½•æ‰€éœ€å­—æ®µï¼šæ ‡é¢˜ã€URLã€æ—¶é—´
- [ ] æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•æˆ–ç‰¹æ®Šè¯·æ±‚å¤´

### 2. é€‰æ‹©å¹¶å¤åˆ¶æ¡ˆä¾‹

æ ¹æ®ä¸Šé¢çš„å†³ç­–æµç¨‹å›¾ï¼Œé€‰æ‹©æœ€æ¥è¿‘çš„æ¡ˆä¾‹è„šæœ¬ï¼š

```bash
# å¤åˆ¶åˆ°å‰ªè´´æ¿
cat .agent/skills/project/create-scraper/examples/sina_tech_roll.py
```

### 3. ç¼–å†™çˆ¬è™«ä»£ç 

åœ¨ **Admin åå° â†’ è‡ªå®šä¹‰æºç®¡ç†** ä¸­åˆ›å»ºï¼Œæ ¸å¿ƒæ¥å£ï¼š

```python
def fetch(config, context):
    """
    Args:
        config (dict): é…ç½®å‚æ•°
        context (dict): ä¸Šä¸‹æ–‡ {
            'now': datetime,
            'use_scraperapi': bool,
            'platform_id': str,
            ...
        }
    
    Returns:
        list: [
            {
                "title": "æ ‡é¢˜",
                "url": "é“¾æ¥",
                "time": "2026-01-15 10:00",  # å¯é€‰
                "rank": 1,                    # å¯é€‰
                "published_at": 1705284000    # å¯é€‰(Unixæ—¶é—´æˆ³)
            }
        ]
    """
    # ä½ çš„ä»£ç 
    return items
```

### 4. æµ‹è¯•çˆ¬è™«

åœ¨ Admin åå°ç‚¹å‡» **"æµ‹è¯•è¿è¡Œ"** éªŒè¯è¾“å‡ºï¼š
- âœ… è¿”å›åˆ—è¡¨æ ¼å¼
- âœ… æ¯ä¸ªæ¡ç›®åŒ…å« `title` å’Œ `url`
- âœ… æ—¶é—´æ ¼å¼æ­£ç¡®
- âœ… æ— å¼‚å¸¸é”™è¯¯

### 5. æ¸…ç†æµ‹è¯•è„šæœ¬ âš ï¸

> [!IMPORTANT]
> **æµ‹è¯•å®Œæˆåï¼ŒåŠ¡å¿…åˆ é™¤é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ä¸´æ—¶è„šæœ¬ï¼**

#### æ–¹æ³•ä¸€ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶æ¸…ç†ï¼ˆæ¨èï¼‰

```bash
# è¿è¡Œæ¸…ç†è„šæœ¬ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶æç¤ºåˆ é™¤
./scripts/cleanup_temp_scripts.sh
```

è„šæœ¬ä¼šæ£€æµ‹ä»¥ä¸‹æ–‡ä»¶ï¼š
- `debug_*.py` - è°ƒè¯•è„šæœ¬
- `scrape_*.py` - ä¸´æ—¶çˆ¬è™«è„šæœ¬  
- `test_*.py` - æµ‹è¯•è„šæœ¬

#### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨æ¸…ç†

```bash
# æ£€æŸ¥ä¸´æ—¶è„šæœ¬
ls -la *.py | grep -E "debug_|scrape_|test_"

# åˆ é™¤ä¸´æ—¶è„šæœ¬  
rm debug_*.py scrape_*.py test_*.py
```

**æœ€ä½³å®è·µ**ï¼š
- âœ… ç›´æ¥åœ¨ Admin åå°ç¼–å†™å’Œæµ‹è¯•ï¼Œæ— éœ€æœ¬åœ°æ–‡ä»¶
- âœ… å¦‚éœ€æœ¬åœ°æµ‹è¯•ï¼Œä½¿ç”¨ `/tmp/` ç›®å½•
- âœ… ä½¿ç”¨ä¸€è‡´çš„å‘½åå‰ç¼€ï¼ˆå¦‚ `temp_`, `debug_`ï¼‰ä¾¿äºæ¸…ç†

### 6. é…ç½®åˆ†ç±»

å°†æ–°æºåˆ†é…åˆ°åˆé€‚çš„æ ç›®åˆ†ç±»ï¼ˆå¦‚"ç§‘æŠ€"ã€"è´¢ç»"ç­‰ï¼‰

---

## ğŸ› ï¸ DynamicPyProvider æ²™ç®±ç¯å¢ƒ

### å¯ç”¨æ¨¡å—ï¼ˆæ— éœ€ importï¼‰

```python
# ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å…¨å±€å˜é‡
requests    # HTTP è¯·æ±‚
bs4         # BeautifulSoupï¼ˆHTML è§£æï¼‰
re          # æ­£åˆ™è¡¨è¾¾å¼
json        # JSON å¤„ç†
datetime    # æ—¥æœŸæ—¶é—´
time        # æ—¶é—´å·¥å…·
hashlib     # å“ˆå¸Œè®¡ç®—
etree       # xml.etree.ElementTree
```

### ç‰¹æ®Šå‡½æ•°

#### `scraperapi_get()` - ScraperAPI è¯·æ±‚

ç”¨äºç»•è¿‡åçˆ¬è™«å’Œæ¸²æŸ“ JavaScriptï¼š

```python
# åŸºç¡€ç”¨æ³•
resp = scraperapi_get(url, use_scraperapi=True)

# æ¸²æŸ“ JSï¼ˆå¦‚ cls_depth æ¡ˆä¾‹ï¼‰
resp = scraperapi_get(
    url, 
    use_scraperapi=True,
    scraperapi_params={"render": "true", "country_code": "us"},
    timeout=60
)
```

**å‰ææ¡ä»¶**ï¼š
1. Admin åå°å¼€å¯"ä½¿ç”¨ ScraperAPI"
2. è®¾ç½®ç¯å¢ƒå˜é‡ `SCRAPERAPI_KEY`

---

## ğŸ’¡ å®æˆ˜æŠ€å·§

### æ—¶é—´æ ¼å¼å¤„ç†

```python
# Unix æ—¶é—´æˆ³ â†’ å­—ç¬¦ä¸²
import time
time_str = time.strftime("%Y-%m-%d %H:%M", time.localtime(1705284000))
# "2026-01-15 10:00"

# å­—ç¬¦ä¸² â†’ datetime
from datetime import datetime
dt = datetime.strptime("2026-01-15 10:00", "%Y-%m-%d %H:%M")
```

### å»é‡å¤„ç†

```python
seen_ids = set()
for item in items:
    item_id = item.get("id")
    if item_id in seen_ids:
        continue
    seen_ids.add(item_id)
    results.append(item)
```

### é”™è¯¯å®¹é”™

```python
try:
    resp = requests.get(url, headers=headers, timeout=10)
    resp.raise_for_status()  # æ£€æŸ¥ HTTP çŠ¶æ€ç 
except Exception as e:
    print(f"è¯·æ±‚å¤±è´¥: {e}")
    return []  # è¿”å›ç©ºåˆ—è¡¨ï¼Œé¿å…å´©æºƒ
```

### é€’å½’éå†åµŒå¥— JSON

å‚è€ƒ `nba_schedule_recursive.py`ï¼š

```python
stack = [data]
while stack:
    cur = stack.pop()
    if isinstance(cur, dict):
        if "ç›®æ ‡å­—æ®µ" in cur:  # è¯†åˆ«ç›®æ ‡å¯¹è±¡
            results.append(cur)
        else:
            stack.extend(cur.values())
    elif isinstance(cur, list):
        stack.extend(cur)
```

---

## âš ï¸ å¸¸è§é™·é˜±

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| è¿”å›ç©ºåˆ—è¡¨ | URL æˆ–å‚æ•°é”™è¯¯ | åœ¨æµè§ˆå™¨ä¸­éªŒè¯ API å“åº” |
| æ—¶é—´æ ¼å¼ä¸å¯¹ | æœªè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ | ä½¿ç”¨ `strftime()` ç»Ÿä¸€æ ¼å¼ |
| ç¼–ç é”™è¯¯ | ä¸­æ–‡ä¹±ç  | è®¾ç½® `resp.encoding = 'utf-8'` |
| è¶…æ—¶ | ç½‘ç»œæ…¢æˆ–åçˆ¬è™« | å¢åŠ  `timeout`ï¼Œè€ƒè™‘ ScraperAPI |
| JS åŠ¨æ€å†…å®¹æŠ“ä¸åˆ° | éœ€è¦æµè§ˆå™¨æ¸²æŸ“ | ä½¿ç”¨ `scraperapi_get()` + render |

---

## ğŸ“š å‚è€ƒä¿¡æ¯

- [æˆåŠŸæ¡ˆä¾‹è¯¦è§£](examples/README.md) - 5 ä¸ªç”Ÿäº§æ¡ˆä¾‹çš„æŠ€æœ¯è¦ç‚¹
- [DynamicPyProvider æºç ](../../hotnews/kernel/providers/dynamic_py.py) - æ²™ç®±å®ç°ç»†èŠ‚
